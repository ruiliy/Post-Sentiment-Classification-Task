{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of TaD Coursework Skeleton 2021 - May-June",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gv2i9fNDvrg"
      },
      "source": [
        "## Post Sentiment Classification Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG9BpbQt3-ko"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_train.json\")\n",
        "\n",
        "validation_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_validation.json\")\n",
        "\n",
        "test_data = pd.read_json(\"https://raw.githubusercontent.com/rpsoft/tad_course/main/reddit_sentiment_test.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REvXkGRbdx0i"
      },
      "source": [
        "# Your code here\n",
        "#import\n",
        "import sys\n",
        "import spacy\n",
        "import itertools\n",
        "# Load the small english model.\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
        "nlp.remove_pipe('tagger')\n",
        "nlp.remove_pipe('parser')\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.dummy import DummyClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpjUDv4gawBU"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  eval = []\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  eval.append(precision)\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  eval.append(recall)\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1,average='macro') #1 means f_1 measure\n",
        "\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
        "  print(classification_report(predictions, true_labels, digits=3, zero_division = 0))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions)) # Note the order here is true, predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NGGtMuA8qZ0"
      },
      "source": [
        "#process the data\n",
        "#reset the index\n",
        "train_data.reset_index(drop=True, inplace=True)\n",
        "validation_data.reset_index(drop=True, inplace=True)\n",
        "test_data.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5HHni6e3Nli8",
        "outputId": "b8c777fc-cd55-4bf7-ac81-77d174fcf875"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>id</th>\n",
              "      <th>url</th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>majority_type</th>\n",
              "      <th>is_first_post</th>\n",
              "      <th>post_depth</th>\n",
              "      <th>in_reply_to</th>\n",
              "      <th>sentiment.polarity</th>\n",
              "      <th>sentiment.subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7f317</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>It's a sad realization, isn't it?</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7erc5</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7hlyf</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>I told her a couple of minutes ago that I didn...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7erc5</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.483631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7etrr</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>TreatYoSelves</td>\n",
              "      <td>Leeches don't make good friends.</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_3xshx9</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7hhpq</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>Melodrama_</td>\n",
              "      <td>I just ended it. Apparently she wasn't a good ...</td>\n",
              "      <td>elaboration</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_cy7etrr</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relationships</td>\n",
              "      <td>My Friend/Crush [22/F] acting weird after I [2...</td>\n",
              "      <td>t1_cy7q0qg</td>\n",
              "      <td>https://www.reddit.com/r/relationships/comment...</td>\n",
              "      <td>TreatYoSelves</td>\n",
              "      <td>Good for you!  Make sure you stick with it.</td>\n",
              "      <td>appreciation</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>t1_cy7hhpq</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.744444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12133</th>\n",
              "      <td>reddit.com</td>\n",
              "      <td>If I announced myself as God right now, would ...</td>\n",
              "      <td>t1_c1zpyd0</td>\n",
              "      <td>https://www.reddit.com/r/reddit.com/comments/h...</td>\n",
              "      <td></td>\n",
              "      <td>If you were God, you'd know whether we would b...</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_hzu51</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12134</th>\n",
              "      <td>reddit.com</td>\n",
              "      <td>If I announced myself as God right now, would ...</td>\n",
              "      <td>t1_c1zpz7m</td>\n",
              "      <td>https://www.reddit.com/r/reddit.com/comments/h...</td>\n",
              "      <td>TheCannon</td>\n",
              "      <td>If I check my account balance in 5 minutes and...</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_hzu51</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12135</th>\n",
              "      <td>reddit.com</td>\n",
              "      <td>If I announced myself as God right now, would ...</td>\n",
              "      <td>t1_c1zq0tl</td>\n",
              "      <td>https://www.reddit.com/r/reddit.com/comments/h...</td>\n",
              "      <td>alllie</td>\n",
              "      <td>I don't know. Can you heal the sick with a tou...</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_hzu51</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.637202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12136</th>\n",
              "      <td>reddit.com</td>\n",
              "      <td>If I announced myself as God right now, would ...</td>\n",
              "      <td>t1_c1zq19j</td>\n",
              "      <td>https://www.reddit.com/r/reddit.com/comments/h...</td>\n",
              "      <td>TheCannon</td>\n",
              "      <td>... Give LeBron James a championship ring?</td>\n",
              "      <td>humor</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>t1_c1zq0tl</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12137</th>\n",
              "      <td>reddit.com</td>\n",
              "      <td>If I announced myself as God right now, would ...</td>\n",
              "      <td>t1_c1zqg1w</td>\n",
              "      <td>https://www.reddit.com/r/reddit.com/comments/h...</td>\n",
              "      <td>blueiiiis</td>\n",
              "      <td>Well, if you believed it, that'd be one</td>\n",
              "      <td>answer</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>t3_hzu51</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12138 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           subreddit  ... sentiment.subjectivity\n",
              "0      relationships  ...               1.000000\n",
              "1      relationships  ...               0.483631\n",
              "2      relationships  ...               0.600000\n",
              "3      relationships  ...               0.475000\n",
              "4      relationships  ...               0.744444\n",
              "...              ...  ...                    ...\n",
              "12133     reddit.com  ...               0.000000\n",
              "12134     reddit.com  ...               0.000000\n",
              "12135     reddit.com  ...               0.637202\n",
              "12136     reddit.com  ...               0.000000\n",
              "12137     reddit.com  ...               0.000000\n",
              "\n",
              "[12138 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsciX_b44oA-"
      },
      "source": [
        "#replace labels\n",
        "def create_label(x):\n",
        "    if x == 'neutral':\n",
        "      return 2\n",
        "    elif x == 'positive':\n",
        "      return 3\n",
        "    elif x == 'negative':\n",
        "      return 1\n",
        "    elif x == 'very positive':\n",
        "      return 4\n",
        "    elif x == 'very negative':\n",
        "      return 0 \n",
        "\n",
        "labels = []\n",
        "temp = train_data['sentiment.polarity']\n",
        "for i in range(12138):\n",
        "  labels.append(create_label(temp[i]))\n",
        "train_data.insert(12,'labels',labels)\n",
        "\n",
        "\n",
        "labels = []\n",
        "temp = validation_data['sentiment.polarity']\n",
        "for i in range(3109):\n",
        "  labels.append(create_label(temp[i]))\n",
        "validation_data.insert(12,'labels',labels)\n",
        "\n",
        "labels = []\n",
        "temp = test_data['sentiment.polarity']\n",
        "for i in range(4016):\n",
        "  labels.append(create_label(temp[i]))\n",
        "test_data.insert(12,'labels',labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh5v0bxR_zeC",
        "outputId": "b0b83062-017a-44b2-8a0c-ffa8357ca865"
      },
      "source": [
        "#data is imbalance\n",
        "validation_labels = validation_data['labels']\n",
        "validation_labels_counts = validation_labels.value_counts()\n",
        "print (validation_labels_counts.head())\n",
        "\n",
        "train_labels = train_data['labels']\n",
        "train_labels_counts = train_labels.value_counts()\n",
        "print (train_labels_counts.head())\n",
        "\n",
        "test_labels = test_data['labels']\n",
        "test_labels_counts = test_labels.value_counts()\n",
        "print (test_labels_counts.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2    1961\n",
            "3     845\n",
            "1     215\n",
            "4      73\n",
            "0      15\n",
            "Name: labels, dtype: int64\n",
            "2    7679\n",
            "3    3231\n",
            "1     878\n",
            "4     253\n",
            "0      97\n",
            "Name: labels, dtype: int64\n",
            "2    2514\n",
            "3    1102\n",
            "1     282\n",
            "4      86\n",
            "0      32\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp9SXeEGACxJ"
      },
      "source": [
        "#Tokenize\n",
        "def spacy_tokenize(string):\n",
        "  tokens = list()\n",
        "  doc = nlp(string)\n",
        "  for token in doc:\n",
        "    tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "#Normalize\n",
        "def normalize(tokens):\n",
        "  normalized = list()\n",
        "  for token in tokens:\n",
        "    #check letter\n",
        "    if (token.is_alpha):\n",
        "      lemma = token.lemma_.lower().strip() if token.lemma_ != \"-PRON-\" else token.lower_\n",
        "      normalized.append(lemma)\n",
        "  return normalized\n",
        "\n",
        "#Tokenize and normalize\n",
        "def tokenize_normalize(string):\n",
        "  return normalize(spacy_tokenize(string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfXxNuwySBIP"
      },
      "source": [
        "#one hot encoding\n",
        "one_hot_vectorizer = CountVectorizer(tokenizer=tokenize_normalize, binary=True)\n",
        "train_features = one_hot_vectorizer.fit_transform(train_data['body'])\n",
        "validation_features = one_hot_vectorizer.transform(validation_data['body'])\n",
        "test_features = one_hot_vectorizer.transform(test_data['body'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j-Crv5TS_G-",
        "outputId": "36891339-479a-44b9-fa05-f25b4681a8e4"
      },
      "source": [
        "print(validation_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 489)\t1\n",
            "  (0, 735)\t1\n",
            "  (0, 1134)\t1\n",
            "  (0, 1187)\t1\n",
            "  (0, 1418)\t1\n",
            "  (0, 2704)\t1\n",
            "  (0, 4272)\t1\n",
            "  (0, 5007)\t1\n",
            "  (0, 5920)\t1\n",
            "  (0, 5970)\t1\n",
            "  (0, 6931)\t1\n",
            "  (0, 8644)\t1\n",
            "  (0, 9143)\t1\n",
            "  (0, 9146)\t1\n",
            "  (0, 12830)\t1\n",
            "  (0, 13387)\t1\n",
            "  (0, 13451)\t1\n",
            "  (1, 429)\t1\n",
            "  (1, 489)\t1\n",
            "  (1, 681)\t1\n",
            "  (1, 1187)\t1\n",
            "  (1, 1234)\t1\n",
            "  (1, 1992)\t1\n",
            "  (1, 2756)\t1\n",
            "  (1, 3709)\t1\n",
            "  :\t:\n",
            "  (3108, 489)\t1\n",
            "  (3108, 565)\t1\n",
            "  (3108, 1187)\t1\n",
            "  (3108, 1719)\t1\n",
            "  (3108, 1885)\t1\n",
            "  (3108, 4725)\t1\n",
            "  (3108, 5920)\t1\n",
            "  (3108, 6324)\t1\n",
            "  (3108, 6485)\t1\n",
            "  (3108, 6910)\t1\n",
            "  (3108, 7353)\t1\n",
            "  (3108, 9014)\t1\n",
            "  (3108, 9212)\t1\n",
            "  (3108, 9331)\t1\n",
            "  (3108, 9960)\t1\n",
            "  (3108, 10121)\t1\n",
            "  (3108, 11596)\t1\n",
            "  (3108, 11731)\t1\n",
            "  (3108, 12867)\t1\n",
            "  (3108, 13381)\t1\n",
            "  (3108, 13387)\t1\n",
            "  (3108, 13585)\t1\n",
            "  (3108, 13854)\t1\n",
            "  (3108, 14449)\t1\n",
            "  (3108, 15110)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoIWVWLBCRoQ"
      },
      "source": [
        "#rf-idf default settings\n",
        "#raw_tfidf = TfidfVectorizer(sublinear_tf = True,ngram_range=(1,1), max_features = 5000,max_df=0.4)\n",
        "#raw_tfidf = TfidfVectorizer(sublinear_tf = True, ngram_range=(1,1), max_features = 5000, max_df=0.9)\n",
        "raw_tfidf = TfidfVectorizer(sublinear_tf = True, max_features = 8000, max_df=0.8)\n",
        "train_tfidf = raw_tfidf.fit_transform(train_data['body'])\n",
        "test_tfidf = raw_tfidf.transform(test_data['body'])\n",
        "validation_tfidf = raw_tfidf.transform(validation_data['body'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxbuCTvth4oW",
        "outputId": "2ee5c7a1-0cac-4b7e-b852-14dd64f90af6"
      },
      "source": [
        "#dummy_prior for the data\n",
        "dummy_prior = DummyClassifier(strategy='stratified')\n",
        "dummy_prior.fit(train_features, train_labels)\n",
        "print(dummy_prior.score(test_features, test_labels))\n",
        "evaluation_summary(\"Dummy Prior\", dummy_prior.predict(test_features), test_labels)\n",
        "\n",
        "evaluation_summary(\"Dummy Prior\", dummy_prior.predict(train_features), train_labels)\n",
        "\n",
        "dummy_mf = DummyClassifier(strategy='most_frequent')\n",
        "dummy_mf.fit(train_features, train_labels)\n",
        "print(dummy_mf.score(test_features, test_labels))\n",
        "evaluation_summary(\"Dummy Majority\", dummy_mf.predict(test_features), test_labels)\n",
        "evaluation_summary(\"Dummy Majority\", dummy_mf.predict(train_features), train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4865537848605578\n",
            "Evaluation for: Dummy Prior\n",
            "Classifier 'Dummy Prior' has Acc=0.478 P=0.203 R=0.203 F1=0.203\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000        36\n",
            "           1      0.096     0.094     0.095       286\n",
            "           2      0.630     0.630     0.630      2516\n",
            "           3      0.279     0.278     0.278      1103\n",
            "           4      0.012     0.013     0.012        75\n",
            "\n",
            "    accuracy                          0.478      4016\n",
            "   macro avg      0.203     0.203     0.203      4016\n",
            "weighted avg      0.478     0.478     0.478      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0    3   19    9    1]\n",
            " [   2   27  169   78    6]\n",
            " [  24  178 1584  682   46]\n",
            " [   9   76  689  307   21]\n",
            " [   1    2   55   27    1]]\n",
            "Evaluation for: Dummy Prior\n",
            "Classifier 'Dummy Prior' has Acc=0.471 P=0.202 R=0.202 F1=0.202\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.031     0.030     0.030       100\n",
            "           1      0.067     0.066     0.067       896\n",
            "           2      0.621     0.632     0.626      7547\n",
            "           3      0.275     0.267     0.271      3323\n",
            "           4      0.016     0.015     0.015       272\n",
            "\n",
            "    accuracy                          0.471     12138\n",
            "   macro avg      0.202     0.202     0.202     12138\n",
            "weighted avg      0.467     0.471     0.469     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   3    7   57   30    0]\n",
            " [   4   59  560  233   22]\n",
            " [  53  565 4767 2112  182]\n",
            " [  36  248 1996  887   64]\n",
            " [   4   17  167   61    4]]\n",
            "0.625996015936255\n",
            "Evaluation for: Dummy Majority\n",
            "Classifier 'Dummy Majority' has Acc=0.626 P=0.200 R=0.125 F1=0.154\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         0\n",
            "           1      0.000     0.000     0.000         0\n",
            "           2      1.000     0.626     0.770      4016\n",
            "           3      0.000     0.000     0.000         0\n",
            "           4      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.626      4016\n",
            "   macro avg      0.200     0.125     0.154      4016\n",
            "weighted avg      1.000     0.626     0.770      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0    0   32    0    0]\n",
            " [   0    0  282    0    0]\n",
            " [   0    0 2514    0    0]\n",
            " [   0    0 1102    0    0]\n",
            " [   0    0   86    0    0]]\n",
            "Evaluation for: Dummy Majority\n",
            "Classifier 'Dummy Majority' has Acc=0.633 P=0.200 R=0.127 F1=0.155\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         0\n",
            "           1      0.000     0.000     0.000         0\n",
            "           2      1.000     0.633     0.775     12138\n",
            "           3      0.000     0.000     0.000         0\n",
            "           4      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.633     12138\n",
            "   macro avg      0.200     0.127     0.155     12138\n",
            "weighted avg      1.000     0.633     0.775     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0    0   97    0    0]\n",
            " [   0    0  878    0    0]\n",
            " [   0    0 7679    0    0]\n",
            " [   0    0 3231    0    0]\n",
            " [   0    0  253    0    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz_nQQOTzkuI",
        "outputId": "b0909e7b-3473-47d0-99c4-2f90714bc816"
      },
      "source": [
        "#mutiple logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#lr = LogisticRegression(solver='saga', max_iter = 1000,multi_class='ovr')\n",
        "#lr_model = lr.fit(train_features, train_labels)\n",
        "#lr_model.predict(test_features)\n",
        "#evaluation_summary(\"LR onehot\", lr_model.predict(test_features), test_labels)\n",
        "#evaluation_summary(\"LR onehot\", lr_model.predict(train_features), train_labels)\n",
        "#mutiple logistic regression with tf-idf\n",
        "#lr = LogisticRegression(solver='saga',max_iter = 10, penalty = 'l2', C = 50)\n",
        "#lr = LogisticRegression(solver='saga',max_iter = 50, penalty = 'l1', C = 10)\n",
        "lr = LogisticRegression(solver='saga',penalty = 'l1',C = 4, max_iter = 100)\n",
        "lr_model = lr.fit(train_tfidf, train_labels)\n",
        "lr_model.predict(validation_tfidf)\n",
        "evaluation_summary(\"LR onehot\", lr_model.predict(validation_tfidf), validation_labels)\n",
        "evaluation_summary(\"LR onehot\", lr_model.predict(train_tfidf), train_labels)\n",
        "evaluation_summary(\"LR onehot\", lr_model.predict(test_tfidf), test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.787 P=0.524 R=0.654 F1=0.572\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.267     0.400     0.320        10\n",
            "           1      0.447     0.627     0.522       153\n",
            "           2      0.894     0.813     0.852      2157\n",
            "           3      0.672     0.755     0.711       752\n",
            "           4      0.342     0.676     0.455        37\n",
            "\n",
            "    accuracy                          0.787      3109\n",
            "   macro avg      0.524     0.654     0.572      3109\n",
            "weighted avg      0.810     0.787     0.795      3109\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   4    2    9    0    0]\n",
            " [   1   96  113    5    0]\n",
            " [   5   51 1754  145    6]\n",
            " [   0    4  267  568    6]\n",
            " [   0    0   14   34   25]]\n",
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.933 P=0.802 R=0.938 F1=0.860\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.629     0.924     0.748        66\n",
            "           1      0.764     0.950     0.847       706\n",
            "           2      0.980     0.930     0.954      8092\n",
            "           3      0.893     0.938     0.915      3076\n",
            "           4      0.743     0.949     0.834       198\n",
            "\n",
            "    accuracy                          0.933     12138\n",
            "   macro avg      0.802     0.938     0.860     12138\n",
            "weighted avg      0.939     0.933     0.935     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  61   13   21    2    0]\n",
            " [   4  671  196    7    0]\n",
            " [   1   16 7523  139    0]\n",
            " [   0    6  330 2885   10]\n",
            " [   0    0   22   43  188]]\n",
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.791 P=0.535 R=0.648 F1=0.579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.344     0.579     0.431        19\n",
            "           1      0.408     0.605     0.487       190\n",
            "           2      0.891     0.821     0.855      2730\n",
            "           3      0.708     0.767     0.736      1017\n",
            "           4      0.326     0.467     0.384        60\n",
            "\n",
            "    accuracy                          0.791      4016\n",
            "   macro avg      0.535     0.648     0.579      4016\n",
            "weighted avg      0.811     0.791     0.798      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  11    6   15    0    0]\n",
            " [   4  115  157    5    1]\n",
            " [   4   65 2241  191   13]\n",
            " [   0    4  300  780   18]\n",
            " [   0    0   17   41   28]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dIFAsiT3J9z",
        "outputId": "9fae2633-5c60-423f-c502-f18247d60260"
      },
      "source": [
        "#logistic regression modift\n",
        "#lor = LogisticRegression(penalty='l1',C=100,multi_class='ovr') \n",
        "lr = LogisticRegression(multi_class='ovr',solver='saga')\n",
        "lr_model = lr.fit(train_features, train_labels)\n",
        "lr_model.predict(validation_features)\n",
        "evaluation_summary(\"LR onehot\", lr_model.predict(validation_features), validation_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.722 P=0.354 R=0.635 F1=0.392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.067     0.500     0.118         2\n",
            "           1      0.158     0.548     0.245        62\n",
            "           2      0.886     0.749     0.812      2319\n",
            "           3      0.550     0.650     0.596       715\n",
            "           4      0.110     0.727     0.190        11\n",
            "\n",
            "    accuracy                          0.722      3109\n",
            "   macro avg      0.354     0.635     0.392      3109\n",
            "weighted avg      0.791     0.722     0.748      3109\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   1    2   10    2    0]\n",
            " [   0   34  175    6    0]\n",
            " [   1   22 1737  198    3]\n",
            " [   0    4  376  465    0]\n",
            " [   0    0   21   44    8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc3QlpXZ8Xx_",
        "outputId": "fa1bc630-3ddd-4ff4-f2f3-18ebff84dbc5"
      },
      "source": [
        "#decision tree\n",
        "from sklearn import tree\n",
        "tree = tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth=30)\n",
        "tree_model = tree.fit(train_features, train_labels)\n",
        "tree_model.predict(train_features)\n",
        "evaluation_summary(\"DT onehot\", tree_model.predict(train_features), train_labels)\n",
        "tree_model.predict(test_features)\n",
        "evaluation_summary(\"DT onehot\", tree_model.predict(test_features), test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.884 P=0.701 R=0.949 F1=0.791\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.515     1.000     0.680        50\n",
            "           1      0.551     0.927     0.691       522\n",
            "           2      0.988     0.853     0.915      8900\n",
            "           3      0.751     0.975     0.849      2487\n",
            "           4      0.700     0.989     0.819       179\n",
            "\n",
            "    accuracy                          0.884     12138\n",
            "   macro avg      0.701     0.949     0.791     12138\n",
            "weighted avg      0.915     0.884     0.890     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  50    0   47    0    0]\n",
            " [   0  484  390    3    1]\n",
            " [   0   36 7589   54    0]\n",
            " [   0    2  802 2426    1]\n",
            " [   0    0   72    4  177]]\n",
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.676 P=0.400 R=0.469 F1=0.425\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.250     0.333     0.286        24\n",
            "           1      0.294     0.474     0.363       175\n",
            "           2      0.842     0.728     0.781      2905\n",
            "           3      0.449     0.582     0.507       851\n",
            "           4      0.163     0.230     0.190        61\n",
            "\n",
            "    accuracy                          0.676      4016\n",
            "   macro avg      0.400     0.469     0.425      4016\n",
            "weighted avg      0.721     0.676     0.693      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   8    7   17    0    0]\n",
            " [   8   83  171   19    1]\n",
            " [   8   76 2116  303   11]\n",
            " [   0    9  563  495   35]\n",
            " [   0    0   38   34   14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "053vPKzSJbjO",
        "outputId": "f5be21e7-7af7-4eee-8ad4-8f9119a1ffbe"
      },
      "source": [
        "#svc\n",
        "from sklearn import svm\n",
        "#clf = svm.SVC(C=1, kernel='linear', decision_function_shape='ovr')\n",
        "clf = svm.SVC(decision_function_shape='ovr')\n",
        "clf_model = clf.fit(train_features, train_labels)\n",
        "clf_model.predict(test_features)\n",
        "evaluation_summary(\"SVM onehot\", clf_model.predict(test_features), test_labels)\n",
        "evaluation_summary(\"SVM onehot\", clf_model.predict(train_features), train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.722 P=0.293 R=0.405 F1=0.295\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         0\n",
            "           1      0.039     0.579     0.073        19\n",
            "           2      0.934     0.723     0.815      3245\n",
            "           3      0.493     0.722     0.586       752\n",
            "           4      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.722      4016\n",
            "   macro avg      0.293     0.405     0.295      4016\n",
            "weighted avg      0.847     0.722     0.769      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0    4   26    2    0]\n",
            " [   0   11  264    7    0]\n",
            " [   0    3 2347  164    0]\n",
            " [   0    1  558  543    0]\n",
            " [   0    0   50   36    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR onehot\n",
            "Classifier 'LR onehot' has Acc=0.855 P=0.418 R=0.740 F1=0.444\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         0\n",
            "           1      0.281     0.972     0.436       254\n",
            "           2      0.976     0.841     0.903      8916\n",
            "           3      0.815     0.888     0.850      2964\n",
            "           4      0.016     1.000     0.031         4\n",
            "\n",
            "    accuracy                          0.855     12138\n",
            "   macro avg      0.418     0.740     0.444     12138\n",
            "weighted avg      0.922     0.855     0.880     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0    5   89    3    0]\n",
            " [   0  247  616   15    0]\n",
            " [   0    2 7495  182    0]\n",
            " [   0    0  599 2632    0]\n",
            " [   0    0  117  132    4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrEFSewqGUWy"
      },
      "source": [
        "#tabel for result\n",
        "data=np.random.randn(6,4)#创建一个6行4列的数组\n",
        "Accuracy and weighted average precision / recall / F1\n",
        "df=pd.DataFrame(data,columns=['Dummy1','Dummy2','LogisticRegression1','LogisticRegression2','SVC Classifier','decision tree'],index=['accuracy','precision','recall','f1'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4eSqU5IVNwTo",
        "outputId": "5aeb8891-b6ef-4f51-bf5a-a9c114f0ee50"
      },
      "source": [
        "#f1 bar chart\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "\n",
        "mpl.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
        "mpl.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "train = [0.484,0.751,0.930,0.875,0.687]\n",
        "test = [0.059,0.242,0.804,0.602,0.081]\n",
        "x = np.arange(5)\n",
        "bar_width = 0.35\n",
        "tick_label = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"negative\"]\n",
        "\n",
        "plt.bar(x, train, bar_width, align=\"center\", color=\"c\", label=\"train\", alpha=0.5)\n",
        "plt.bar(x+bar_width, test, bar_width, color=\"b\", align=\"center\", label=\"test\", alpha=0.5)\n",
        "\n",
        "plt.xlabel(\"classes\")\n",
        "plt.ylabel(\"F1 socre\")\n",
        "\n",
        "plt.xticks(x+bar_width/2, tick_label)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZZElEQVR4nO3de7zVdZ3v8debi2xQBAO0UbRNRl5S88IhTc9kmYlOB/NkjhdqtI47JyWmRo/aUUNnpmGiR5nltcZ0MkZRHxZjmKhpelQURERAFAQdNs5JRDFRULDP+eP33bLcrL3ZG/ZvLfb+vp+Px37s3239fp/fb13e63f7LkUEZmaWr171LsDMzOrLQWBmljkHgZlZ5hwEZmaZcxCYmWWuT70L6KyhQ4dGY2NjvcswM+tWnnjiiVciYli1cd0uCBobG5k9e3a9yzAz61YkvdjWOB8aMjPLnIPAzCxzDgIzs8x1u3MEZmZbYv369TQ3N7Nu3bp6l1KqhoYGhg8fTt++fTv8GAeBmWWhubmZgQMH0tjYiKR6l1OKiGDVqlU0NzczYsSIDj/Oh4bMLAvr1q1jyJAhPTYEACQxZMiQTu/1OAjMLBs9OQRabMk6OgjMzDLncwRmlqWJy5Z17fw2c0x+9erVTJkyhW984xudmu9xxx3HlClTGDx48NaU1y4HgWWnqz8A3ptvJ07OWX5Wr17NVVddtUkQbNiwgT592v4onj59etmlOQjMzGrhggsu4Pnnn+fAAw+kb9++NDQ0sNNOO7Fo0SKee+45vvCFL7B8+XLWrVvHhAkTaGpqAjY2q7NmzRqOPfZYjjjiCB555BF22203fvOb39C/f/+trs3nCMzMamDSpEnsueeezJ07l8mTJzNnzhx+/OMf89xzzwFw/fXX88QTTzB79myuuOIKVq1atck8Fi9ezNlnn82CBQsYPHgwt99+e5fU5j0CM7M6GD169Puu9b/iiiu44447AFi+fDmLFy9myJAh73vMiBEjOPDAAwE45JBDeOGFF7qkFgeBmVkdbL/99u91P/DAA9x77708+uijDBgwgCOPPLLqvQD9+vV7r7t3796sXbu2S2rxoSEzsxoYOHAgb7zxRtVxr7/+OjvttBMDBgxg0aJFzJw5s6a1eY/AzLJU66u8hgwZwuGHH85+++1H//792WWXXd4bN2bMGK655hr22Wcf9tprLw499NCa1uYgMDOrkSlTplQd3q9fP+66666q41rOAwwdOpT58+e/N/zcc8/tsrp8aMjMLHMOAjOzzDkIzMwy5yAwM8ucTxabZcjtLVkl7xGYmWXOewRmlqWJE2s7vy1thhrg8ssvp6mpiQEDBmxZcZvhPQIzsxpoaYZ6S1x++eW89dZbXVzRRt4jMDOrgcpmqI8++mh23nlnpk6dyttvv80JJ5zApZdeyptvvslJJ51Ec3Mz7777LhdffDF//OMfeemll/j0pz/N0KFDuf/++7u8NgeBmVkNTJo0ifnz5zN37lxmzJjBbbfdxuOPP05EMHbsWB588EFWrlzJrrvuym9/+1ugaINo0KBB/PCHP+T+++9n6NChpdTmQ0NmZjU2Y8YMZsyYwUEHHcTBBx/MokWLWLx4Mfvvvz/33HMP559/Pg899BCDBg2qST3eIzAzq7GI4MILL+TrX//6JuPmzJnD9OnTueiiizjqqKO45JJLSq/HewRmZjVQ2Qz1Mcccw/XXX8+aNWsAWLFiBS+//DIvvfQSAwYMYNy4cZx33nnMmTNnk8eWwXsEZpalrr58dHMqm6E+9thjOfXUUznssMMA2GGHHbjppptYsmQJ5513Hr169aJv375cffXVADQ1NTFmzBh23XVXnyw2M+vOWjdDPWHChPf177nnnhxzzDGbPG78+PGMHz++tLp8aMjMLHMOAjOzzDkIzCwbEVHvEkq3JetYahBIGiPpWUlLJF1QZfweku6X9KSkeZKOK7MeM8tXQ0MDq1at6tFhEBGsWrWKhoaGTj2utJPFknoDVwJHA83ALEnTImJhxWQXAVMj4mpJ+wLTgcayajKzfA0fPpzm5mZWrlxZ71JK1dDQwPDhwzv1mDKvGhoNLImIpQCSbgaOByqDIIAdU/cg4KUS6zErVZmXI9b6UseeqG/fvozw7yVUVeahod2A5RX9zWlYpYnAOEnNFHsDVa+PktQkabak2T09zc3Maq3eJ4tPAW6IiOHAccAvJW1SU0RcFxGjImLUsGHDal6kmVlPVmYQrAB2r+gfnoZV+howFSAiHgUagHKa1zMzs6rKDIJZwEhJIyRtB5wMTGs1zX8CRwFI2ociCHzsx8yshkoLgojYAJwD3A08Q3F10AJJl0kamyb7e+BMSU8B/w6cHj352i4zs21QqW0NRcR0ipPAlcMuqeheCBxeZg1mZta+ep8sNjOzOnMQmJllzkFgZpY5B4GZWeYcBGZmmfMvlGVm4rJl5c3b7biYdUveIzAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5xbHzWz7LgV3vfzHoGZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGZmmXMQmJllrtQgkDRG0rOSlki6oI1pTpK0UNICSVPKrMfMzDZV2g/TSOoNXAkcDTQDsyRNi4iFFdOMBC4EDo+I1yTtXFY9ZmZWXZl7BKOBJRGxNCLeAW4Gjm81zZnAlRHxGkBEvFxiPWZmVkWZP1W5G7C8or8Z+ESraT4KIOlhoDcwMSJ+13pGkpqAJoA99tijlGLNbOtNnNg95527ep8s7gOMBI4ETgF+Jmlw64ki4rqIGBURo4YNG1bjEs3MerYyg2AFsHtF//A0rFIzMC0i1kfEMuA5imAwM7MaKTMIZgEjJY2QtB1wMjCt1TS/ptgbQNJQikNFS0usyczMWiktCCJiA3AOcDfwDDA1IhZIukzS2DTZ3cAqSQuB+4HzImJVWTWZmdmmyjxZTERMB6a3GnZJRXcA305/ZmZWBx3aI5B0hKQzUvcwSSPKLcvMzGpls0Eg6bvA+RQ3fgH0BW4qsygzM6udjuwRnACMBd4EiIiXgIFlFmVmZrXTkSB4Jx3LDwBJ25dbkpmZ1VJHgmCqpGuBwZLOBO4FflZuWWZmVivtXjUkScAtwN7An4C9gEsi4p4a1GZmZjXQbhBEREiaHhH7A/7wNzPrgTpyaGiOpP9WeiVmZlYXHbmh7BPAaZJepLhySBQ7CweUWpmZmdVER4LgmNKrMDOzuunIoaG/AF6NiBcj4kXgNeCD5ZZlZma10pEguBpYU9G/Jg0zM7MeoCNBoHRDGQAR8WdKbqzOzMxqpyNBsFTSNyX1TX8T8G8GmJn1GB0JgrOAT1L8utgKiquImsosyszMamezh3gi4mWKXxczM7MeqCPNUA+XdIekl9Pf7ZKG16I4MzMrX0cODf2C4reGd01//5GGmZlZD9CRIBgWEb+IiA3p7wZgWMl1mZlZjXQkCFZJGiepd/obB/gH5s3MeoiO3A/wVeAnwI9S/8PAGaVVVKKJy5aVN+8R/hlnM+ueOnLV0IsUP1VpZmY9UEeuGvq+pB3TzWT3SVqZDg+ZmVkP0JFzBJ+LiD8BnwdeAD4CnFdmUWZmVjsdCYKWw0d/BdwaEa+XWI+ZmdVYR04W3ylpEbAW+FtJw4B15ZZlZma1stk9goi4gKKtoVERsR54Czi+7MLMzKw2OtScdES8WtH9JsVPVpqZWQ/QkXMEZmbWgzkIzMwyt0VBIGnvri7EzMzqY0v3CGZ0aRVmZlY3bZ4slnRFW6OAweWUY2ZmtdbeVUNnAH8PvF1l3CnllGNmZrXWXhDMAuZHxCOtR0iaWFpFZmZWU+0FwYm0cQdxRLjNZTOzHqK9k8U7RMRbWzNzSWMkPStpiaQL2pnui5JC0qitWZ6ZmXVee0Hw65YOSbd3dsaSegNXAscC+wKnSNq3ynQDgQnAY51dhpmZbb32gkAV3R/egnmPBpZExNKIeAe4meptFP0D8C+4ITszs7poLwiije6O2g1YXtHfnIa9R9LBwO4R8dv2ZiSpSdJsSbNXrly5BaWYmVlb2jtZ/HFJf6LYM+ifukn9ERE7bs2CJfUCfgicvrlpI+I64DqAUaNGbUkomZlZG9oMgojovZXzXgHsXtE/PA1rMRDYD3hAEsAHgWmSxkbE7K1ctpmZdVCZjc7NAkZKGiFpO+BkYFrLyIh4PSKGRkRjRDQCMwGHgJlZjZUWBBGxATgHuBt4BpgaEQskXSZpbFnLNTOzzunQD9NsqYiYDkxvNeySNqY9ssxazMysOv8egZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5hwEZmaZcxCYmWXOQWBmljkHgZlZ5vrUuwDrOSZO7F7zNbOC9wjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDJXahBIGiPpWUlLJF1QZfy3JS2UNE/SfZI+VGY9Zma2qdKCQFJv4ErgWGBf4BRJ+7aa7ElgVEQcANwGfL+seszMrLoy9whGA0siYmlEvAPcDBxfOUFE3B8Rb6XemcDwEusxM7MqygyC3YDlFf3NaVhbvgbcVW2EpCZJsyXNXrlyZReWaGZm28TJYknjgFHA5GrjI+K6iBgVEaOGDRtW2+LMzHq4MpuYWAHsXtE/PA17H0mfBf4P8KmIeLvEeszMrIoy9whmASMljZC0HXAyMK1yAkkHAdcCYyPi5RJrMTOzNpQWBBGxATgHuBt4BpgaEQskXSZpbJpsMrADcKukuZKmtTE7MzMrSamtj0bEdGB6q2GXVHR/tszlm5nZ5m0TJ4vNzKx+HARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnmHARmZplzEJiZZc5BYGaWOQeBmVnm+tS7ADOznmTixO43b+8RmJllzkFgZpY5B4GZWeYcBGZmmfPJ4i7SHU8QmZmB9wjMzLLnIDAzy5yDwMwscw4CM7PMOQjMzDLnIDAzy5yDwMwscw4CM7PMOQjMzDJXahBIGiPpWUlLJF1QZXw/Sbek8Y9JaiyzHjMz21RpQSCpN3AlcCywL3CKpH1bTfY14LWI+AjwI+BfyqrHzMyqK3OPYDSwJCKWRsQ7wM3A8a2mOR64MXXfBhwlSSXWZGZmrSgiypmxdCIwJiL+V+r/MvCJiDinYpr5aZrm1P98muaVVvNqAppS717As6UUvXWGAq9sdqqeLfdtkPv6g7cBbLvb4EMRMazaiG7R+mhEXAdcV+862iNpdkSMqncd9ZT7Nsh9/cHbALrnNijz0NAKYPeK/uFpWNVpJPUBBgGrSqzJzMxaKTMIZgEjJY2QtB1wMjCt1TTTgL9J3ScCv4+yjlWZmVlVpR0aiogNks4B7gZ6A9dHxAJJlwGzI2Ia8K/ALyUtAV6lCIvuaps+dFUjuW+D3NcfvA2gG26D0k4Wm5lZ9+A7i83MMucgMDPLnINgGyLpO636H6lXLVtL0mBJ36jo31XSbfWsqRYkNUo6dQsfu6ar66klSWdJ+krqPl3SrhXjfl6lZYEer7u8D7I+R5DuYlZE/LnetUDxQRARO9S7jq6Q2o26MyL2q3MpNSXpSODciPh8lXF9ImJDO4/tSc//AxTbYXa9a6mnbvM+iIhu/QdMAs6u6J9I8QIEOI/iMtZ5wKVpWCPFncn/BiwAvgtcXvH4M4EfVVnOGuCfgKeAmcAuafgw4Pa0nFnA4RXD70nL+DnwIjA0jfs18EQa11SxHu8Cc4FftSwz/b8Z+KuKWm6guNy2NzC5Yh2/3ont1gg8A/ws1TED6A/sCfwu1fcQsHeafs+03k8D/1hR2w7AfcCcNO74iprXpvWZnJY3P42bCXysopYHgFHA9sD1wOPAky3zqtHrqLPb4wbgxMrXR8W6vZ7W+1vA6RSXSf8e+ENb26tyHnV6HzUCi4Bfpe1wGzAAOCo9F0+n56Zfxet1YXrd/aDyvZdem2so3mdz03ZseY7PAiZXLPd04Kepe1x67ucC1wK9t8HnvUe+D+ryouviJ/Ig4A8V/QspblL7HMVlXKI4BHYn8JfpifgzcGjFE/g80Df1PwLsX2U5AfyP1P194KLUPQU4InXvATyTun8KXJi6x6THtwTBB9L//sB8YEjqX9NqmS0vshOAG1P3dsDy9Nimijr6AbOBEZ14A2wADkz9U9Mb8T5gZBr2CYp7O0jb75TUfVZFbX2AHVP3UGBJ2ubvveArltfyBvgWG4P5L4BnU/f3gHGpezDwHLB9jV5Hnd0eN1A9CI6k+AbYMvx0oLniOa+6vao9/zV+HzWm12jLF5nrgYvSa+2jadi/AX8HDKH4kG+pe3D6P5GNX8IeAEZVzP8Big+5YRRtkLUMvws4AtgH+A82vg+vAr6yDT7vPfJ90C2amGhPRDwpaed0PHIYRWumyyVNoAiDJ9OkOwAjgf8EXoyImenxayT9Hvi8pGcoXohPV1nUOxQvAii+JRyduj8L7FvRVt6OknageHGfkJbxO0mvVczrm5JOSN27p7rau6P6LuDHkvpRhMqDEbFW0ueAA1K7TlDcmT0SWNbOvCoti4i5FevUCHwSuLViffql/4cBX0jdU4AfpG4B35P0lxQBuxuwy2aWO5Xim9d3gZMovn1C8XyNlXRu6m8ghWsH12drdWZ7dMY9EfFq6m5re/2/LS26Cy2PiIdT903AxRTb5Lk07EbgbIovOeuAf5V0JxvfF5sVESslLZV0KLAY2Bt4OM33EGBW2tb9gZe3fpU6JPv3QbcPguRWit3RDwK3pGEC/jkirq2cMB2ze7PV438OfIdi1/gXbSxjfaSIpjiE07LtelHsXaxrtZyqM0nHkD8LHBYRb6VjqQ1trhkQEevSdMcAf02xuwnFOo6PiLvbe3w73q7ofpfihbs6Ig7sxDxOowjgQyJivaQX2Pz6rJC0StIBFOtzVhol4IsRUa9GBTuzPTaQLraQ1ItiT60tla+3Tm+vGmp9wnA1xbf/909U3Cw6muKw0YnAOcBnOrGcmyk++BYBd0REpPN1N0bEhVtU+dbJ/n3QU64auoXiruQTKUIBijuav5q+nSNpN0k7V3twRDxG8c38VODfO7nsGcD4lh5JLS+ehyle7KRv7jul4YMo9lrekrQ3cGjFvNZL6tvGcm4BzgD+O8WxSyjW8W9bHiPpo5K272T9lf4ELJP0pTQ/Sfp4GjcT+GLqrrwDfBDwcnrxfxr4UBr+BjCwnWXdAvxvYFBEzKtYn/EtTZFLOmgr1qUrtLc9XqD4BgswFmh53ja33m1tr23BHpIOS92nUhxqbJT0kTTsy8Af0ntqUERMpzi88fFNZ9XudriDogn6U9j4peY+4MSW96ikD0iq17bJ7n3QI4IgIhZQbOwVEfFfadgMil23RyU9TbHb1d4TMhV4OCJea2eaar4JjJI0T9JCNqb6pcDnVDS1/SWKXf83KD7E+6TDUJMoXlgtrgPmSfpVleXMAD4F3BvF7ztAsSezEJiTlnMtW7+XdxrwNUlPUZw8a/kNib8Dvi1pHvARihOiUJxcHJW28VcovuUREauAhyXNlzS5ynJuo3gjTa0Y9g8UH6jzJC1I/fXW1vb4GfCpNPwwNn7rnwe8K+kpSd+qMr+q22sb8Sxwdnpt7kTxY1FnUBwieZrikMc1FO+jO9Nr4f8C364yrxuAayTNldS/ckR6jz1D0Szy42nYQopzEjPSfO+hOG5eL1m9D7K+fLRSOtb5o4i4r4vm1w94N+1GHwZc3cldzW2KpAHA2rQbfzLFCbPWPzRk3VS3ucyxznrq+6CnnCPYYpIGU1ym9VRXhUCyBzA1HT9+h+Ky1O7sEOCnaXd1NfDVOtdjVg898n3gPQIzs8z1iHMEZma25RwEZmaZcxCYmWXOQWDWBkkTK+7uNOuxHARmZplzEJglkr6Sbgx8StIvW407U9KsNO72dD05kr6UbhZ6StKDadjHJD2ebqaaJ2lkGj6uYvi1knqnvxvSPJ5u4yY0s1L58lEzig9viqYPPhkRr0j6AMVd42si4geShqS7RJH0j8AfI+In6U7SMandmMERsVrST4CZEfErSdtRNBfeSNFq7f9MzRBcRXFX+QJgUkQcneY9OCJW13j1LXPeIzArfAa4NSJeAahoLbTFfpIeSh/8pwEfS8MfBm6QdCbFBz7Ao8B3JJ1P0YzCWooG2lpa15yb+j8MLAU+LOknksZQtHNjVlMOArOOuQE4JyL2p2hHqgEgIs6iaCNnd+CJtOcwhaIhurXAdEmfoWhR8saIODD97RURE1O7Ox+naK//LIr2o8xqykFgVvg98CVJQ6Bo/bLV+IHAf6lo6fW0loGS9oyIxyLiEmAlsLukDwNLI+IK4DfAAbTRuqakoUCviLidIlAOLnc1zTaVfVtDZlC0YCvpnyiaWX6X4geNXqiY5GLgMYoP+8fY2JLt5HQyWBQf9k8B5wNflrSeotXZ70XEq5JaWtfsBayn+DGWtcAv0jCAerTHb5nzyWIzs8z50JCZWeYcBGZmmXMQmJllzkFgZpY5B4GZWeYcBGZmmXMQmJll7v8DaiGFUn003oUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAHsj1K2SG3X"
      },
      "source": [
        "#using pipline to tune the data\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "prediction_pipeline = Pipeline([\n",
        "              ('selector', ItemSelector(key='reviewText')),\n",
        "              ('one-hot', CountVectorizer(binary=True)),\n",
        "              ('logreg', LogisticRegression(solver='saga', max_iter=9000))\n",
        "              ])\n",
        "prediction_pipeline.fit(train_data, train_labels)\n",
        "evaluation_summary(\"LR\", prediction_pipeline.predict(validation_data), validation_labels) \n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {\n",
        "   'one-hot__binary': (True, False), \n",
        "}\n",
        "grid_search = GridSearchCV(prediction_pipeline, param_grid=params, n_jobs=1, verbose=1, scoring='f1_macro', cv=2)\n",
        "print(\"Performing grid search...\")\n",
        "print(\"pipeline:\", [name for name, _ in prediction_pipeline.steps])\n",
        "print(\"parameters:\")\n",
        "print(params)\n",
        "grid_search.fit(train_data, train_labels)\n",
        "\n",
        "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = grid_search.best_estimator_.get_params()\n",
        "for param_name in sorted(params.keys()):\n",
        "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciWxUwjo94CU"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ItemSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
        "\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_dict):\n",
        "        return data_dict[self.key]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZTkHB8tOtkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286c8d8c-4a1a-47d2-b30d-ef258bb86141"
      },
      "source": [
        "#adding feature\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Use FeatureUnion to combine the features from text and summary\n",
        "prediction_pipeline = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "          transformer_list=[\n",
        "            ('text', Pipeline([\n",
        "              ('selector', ItemSelector(key='body')),\n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf = True, max_features = 8000, max_df=0.8)), \n",
        "              ])),\n",
        "            ('summary1', Pipeline([\n",
        "              ('selector', ItemSelector(key='title')),\n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf = True, max_features = 8000)), \n",
        "              ])),\n",
        "            ('summary2', Pipeline([\n",
        "              ('selector', ItemSelector(key='author')),\n",
        "              ('one-hot', TfidfVectorizer(sublinear_tf = True, max_features = 8000)), \n",
        "              ]))\n",
        "        ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "one_hot_train_features = prediction_pipeline.fit_transform(train_data)\n",
        "one_hot_validation_features = prediction_pipeline.transform(validation_data)\n",
        "one_hot_test_features = prediction_pipeline.transform(test_data)\n",
        "\n",
        "lr = LogisticRegression(solver='saga',penalty = 'l1',C = 4)\n",
        "combined_model = lr.fit(one_hot_train_features,train_labels)\n",
        "evaluation_summary(\"LR TFIDF\", combined_model.predict(one_hot_test_features), test_labels)\n",
        "evaluation_summary(\"LR TFIDF\", combined_model.predict(one_hot_train_features), train_labels)\n",
        "evaluation_summary(\"LR TFIDF\", combined_model.predict(one_hot_validation_features), validation_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: LR TFIDF\n",
            "Classifier 'LR TFIDF' has Acc=0.783 P=0.492 R=0.679 F1=0.551\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.281     0.600     0.383        15\n",
            "           1      0.273     0.602     0.376       128\n",
            "           2      0.915     0.797     0.852      2886\n",
            "           3      0.663     0.776     0.715       942\n",
            "           4      0.326     0.622     0.427        45\n",
            "\n",
            "    accuracy                          0.783      4016\n",
            "   macro avg      0.492     0.679     0.551      4016\n",
            "weighted avg      0.826     0.783     0.798      4016\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   9    6   17    0    0]\n",
            " [   3   77  194    8    0]\n",
            " [   3   40 2300  167    4]\n",
            " [   0    5  353  731   13]\n",
            " [   0    0   22   36   28]]\n",
            "Evaluation for: LR TFIDF\n",
            "Classifier 'LR TFIDF' has Acc=0.987 P=0.964 R=0.993 F1=0.978\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.928     1.000     0.963        90\n",
            "           1      0.958     0.994     0.976       846\n",
            "           2      0.996     0.985     0.991      7766\n",
            "           3      0.977     0.989     0.983      3192\n",
            "           4      0.960     0.996     0.978       244\n",
            "\n",
            "    accuracy                          0.987     12138\n",
            "   macro avg      0.964     0.993     0.978     12138\n",
            "weighted avg      0.987     0.987     0.987     12138\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  90    1    6    0    0]\n",
            " [   0  841   34    3    0]\n",
            " [   0    2 7650   27    0]\n",
            " [   0    2   70 3158    1]\n",
            " [   0    0    6    4  243]]\n",
            "Evaluation for: LR TFIDF\n",
            "Classifier 'LR TFIDF' has Acc=0.767 P=0.469 R=0.632 F1=0.522\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.200     0.429     0.273         7\n",
            "           1      0.353     0.594     0.443       128\n",
            "           2      0.900     0.789     0.841      2236\n",
            "           3      0.619     0.742     0.675       705\n",
            "           4      0.274     0.606     0.377        33\n",
            "\n",
            "    accuracy                          0.767      3109\n",
            "   macro avg      0.469     0.632     0.522      3109\n",
            "weighted avg      0.805     0.767     0.780      3109\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   3    1   11    0    0]\n",
            " [   0   76  136    3    0]\n",
            " [   3   44 1764  144    6]\n",
            " [   1    6  308  523    7]\n",
            " [   0    1   17   35   20]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}